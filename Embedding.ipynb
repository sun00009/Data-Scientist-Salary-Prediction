{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbghY37Xm7NL",
        "outputId": "653c382e-709d-42a4-ee9c-c793a0658e05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark==3.1.2 in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark==3.1.2) (0.10.9)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark==3.1.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sparknlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7QbUyPFm9Bv",
        "outputId": "af3b949a-10d5-46d3-bd79-a71e82524733"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sparknlp in /usr/local/lib/python3.7/dist-packages (1.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sparknlp) (1.21.6)\n",
            "Requirement already satisfied: spark-nlp in /usr/local/lib/python3.7/dist-packages (from sparknlp) (3.4.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "from pyspark import *\n",
        "import sparknlp"
      ],
      "metadata": {
        "id": "sTI2Foc8o1NH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = sparknlp.start()"
      ],
      "metadata": {
        "id": "fchfTgyZo1P2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = spark.read.option('Header',True).csv('/content/train_data.csv')\n",
        "test_data = spark.read.option('Header',True).csv('/content/test_data.csv')"
      ],
      "metadata": {
        "id": "5MpVQKPUo1Sg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiivuI6ko1VJ",
        "outputId": "1315e74c-3204-4c4f-b540-953e6bb0ed45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+\n",
            "|                data|salary|\n",
            "+--------------------+------+\n",
            "|5 7 yrs exp minim...|     5|\n",
            "|10 17 yrs he shou...|     1|\n",
            "|5 9 yrs must be a...|     2|\n",
            "|7 10 yrs 7 10 yea...|     1|\n",
            "|1 3 yrs chartered...|     4|\n",
            "|5 10 yrs 4 willin...|     5|\n",
            "|13 15 yrs experie...|     3|\n",
            "|6 10 yrs qualifie...|     5|\n",
            "|1 3 yrs proven ex...|     0|\n",
            "|2 6 yrs other act...|     2|\n",
            "|3 7 yrs manage la...|     5|\n",
            "|10 12 yrs experie...|     1|\n",
            "|2 6 yrs 3 years o...|     1|\n",
            "|2 4 yrs knowledge...|     5|\n",
            "|1 6 yrs job respo...|     1|\n",
            "|3 6 yrs masters m...|     1|\n",
            "|5 8 yrs 2 years o...|     5|\n",
            "|3 6 yrs 3 years e...|     1|\n",
            "|4 9 yrs work with...|     2|\n",
            "|3 5 yrs experienc...|     5|\n",
            "+--------------------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9jwTYtOo1Xw",
        "outputId": "2763fddf-748d-4c76-94f3-2bc4d606023b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+\n",
            "|                data|\n",
            "+--------------------+\n",
            "|7 12 yrs professi...|\n",
            "|0 5 yrs we are lo...|\n",
            "|3 6 yrs should un...|\n",
            "|0 3 yrs no data a...|\n",
            "|0 5 yrs no data a...|\n",
            "|4 6 yrs 5 6 years...|\n",
            "|10 20 yrs no data...|\n",
            "|0 2 yrs no data a...|\n",
            "|6 8 yrs 6 8 years...|\n",
            "|0 5 yrs no data a...|\n",
            "|10 15 yrs ensure ...|\n",
            "|6 9 yrs 6 years o...|\n",
            "|3 7 yrs at least ...|\n",
            "|8 12 yrs team man...|\n",
            "|3 6 yrs should ha...|\n",
            "|2 4 yrs expertise...|\n",
            "|1 5 yrs should ha...|\n",
            "|0 2 yrs no data a...|\n",
            "|5 10 yrs no data ...|\n",
            "|3 6 yrs the candi...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp.base import *\n",
        "from sparknlp.pretrained import PretrainedPipeline"
      ],
      "metadata": {
        "id": "gToUJpN6qSTn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler = DocumentAssembler()\n",
        "sentence_encoder = UniversalSentenceEncoder.pretrained()\n",
        "embeddings_finisher = EmbeddingsFinisher()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKFCrmKCrOrN",
        "outputId": "4092c772-09a4-4184-9c57-ad90896d9715"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use download started this may take some time.\n",
            "Approximate size to download 923.7 MB\n",
            "[OK!]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "document_assembler.setInputCol('data')\n",
        "document_assembler.setOutputCol('document')\n",
        "\n",
        "sentence_encoder.setInputCols(['document'])\n",
        "sentence_encoder.setOutputCol('sentence_embeddings')\n",
        "\n",
        "embeddings_finisher.setInputCols(\"sentence_embeddings\")\n",
        "embeddings_finisher.setOutputCols(\"finished_sentence_embeddings\")\n",
        "embeddings_finisher.setOutputAsVector(True)\n",
        "embeddings_finisher.setCleanAnnotations(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8a0ZoYzqSWW",
        "outputId": "120c0d8c-2a30-4b63-927d-8ef545526e04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EmbeddingsFinisher_c925f8c7283b"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_pipeline = Pipeline(stages=[\n",
        "    document_assembler, \n",
        "    sentence_encoder,\n",
        "    embeddings_finisher\n",
        "])"
      ],
      "metadata": {
        "id": "HENMPL3YqSZW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_model = nlp_pipeline.fit(train_data.select('data'))\n",
        "embedded_model = pipeline_model.transform(train_data.select('data'))"
      ],
      "metadata": {
        "id": "pJjiMRZSqScQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_model.toPandas().to_csv('train_data_embedded.csv',index=False)"
      ],
      "metadata": {
        "id": "jILCmF3utxeU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_model1 = nlp_pipeline.fit(test_data.select('data'))\n",
        "embedded_model1 = pipeline_model1.transform(test_data.select('data'))"
      ],
      "metadata": {
        "id": "JBmZZZSfv77z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedded_model1.toPandas().to_csv('test_data_embedded.csv',index=False)"
      ],
      "metadata": {
        "id": "Do9gp9HDwYit"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}